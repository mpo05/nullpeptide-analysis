{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Imports for data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Imports for efficient string matching\n",
    "import ahocorasick\n",
    "\n",
    "# Imports for progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Imports for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Imports for data processing\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working paths.\n",
    "DMS_files_path = \"/Volumes/Intenso_SSD/Georgakopoulos_lab/nullp_pathogenesis/DMS/\"\n",
    "DMS_samples_with_subs_path = f\"{DMS_files_path}Substitutions\"\n",
    "DMS_samples_with_indels_path = f\"{DMS_files_path}Indels\"\n",
    "\n",
    "# Set nullpeptides path\n",
    "nullpeptides_path = '/Volumes/Intenso_SSD/Georgakopoulos_lab/nullp_pathogenesis/null_peptides/'\n",
    "\n",
    "# Read files for analysis as pandas dataframes.\n",
    "DMS_samples_with_subs_info_df = pd.read_csv(f\"{DMS_files_path}DMS_substitutions.csv\")\n",
    "DMS_samples_with_indels_info_df = pd.read_csv(f\"{DMS_files_path}DMS_indels.csv\")\n",
    "\n",
    "# Keep only Human experiments.\n",
    "human_only_DMS_samples_with_subs_info_df = DMS_samples_with_subs_info_df[DMS_samples_with_subs_info_df['taxon'] == 'Human']\n",
    "human_only_DMS_samples_with_indels_info_df = DMS_samples_with_indels_info_df[DMS_samples_with_indels_info_df['taxon'] == 'Human']\n",
    "\n",
    "# Save Human only analyses to csv.\n",
    "human_only_DMS_samples_with_subs_info_df.to_csv('/Volumes/Intenso_SSD/Georgakopoulos_lab/nullp_pathogenesis/DMS/human_only_DMS_substitutions.csv')\n",
    "human_only_DMS_samples_with_indels_info_df.to_csv('/Volumes/Intenso_SSD/Georgakopoulos_lab/nullp_pathogenesis/DMS/human_only_DMS_indels.csv')\n",
    "\n",
    "# Set paths to save human samples.\n",
    "human_DMS_samples_with_subs_path = f\"{DMS_samples_with_subs_path}/human_samples\"\n",
    "human_DMS_samples_with_indels_path = f\"{DMS_samples_with_indels_path}/human_samples\"\n",
    "\n",
    "# Define an output directory for each mutation type.\n",
    "modified_subs_path = f\"{human_DMS_samples_with_subs_path}/modified_human_samples\"\n",
    "modified_indels_path = f\"{human_DMS_samples_with_indels_path}/modified_human_samples\"\n",
    "\n",
    "# Specify empty lists to store the dataframe for each sample.\n",
    "modified_human_DMS_samples_with_subs_list = []\n",
    "modified_human_DMS_samples_with_indels_list = []\n",
    "\n",
    "#Specify the output directories for each mutation case.\n",
    "plots_directory = '/Volumes/Intenso_SSD/Georgakopoulos_lab/nullp_pathogenesis/DMS/Plots/'\n",
    "\n",
    "#Specify the output directories for each mutation case.\n",
    "subs_output_directory = f'{plots_directory}/Subs'\n",
    "indels_output_directory = f'{plots_directory}/Indels'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path):\n",
    "    \"\"\"\n",
    "    Creates a directory at the specified path if it does not already exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def copy_human_samples(source_path, destination_path):\n",
    "    \"\"\"\n",
    "    Copies files containing '_HUMAN_' in their name from the source path to the destination path.\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(source_path):\n",
    "        if \"_HUMAN_\" in filename:\n",
    "            source_file = os.path.join(source_path, filename)\n",
    "            destination_file = os.path.join(destination_path, filename)\n",
    "            shutil.copy(source_file, destination_file)\n",
    "\n",
    "# Create paths if they don't exist\n",
    "create_directory(human_DMS_samples_with_subs_path)\n",
    "create_directory(human_DMS_samples_with_indels_path)\n",
    "create_directory(modified_subs_path)\n",
    "create_directory(modified_indels_path)\n",
    "\n",
    "# Copy human DMS samples to their respective new folders\n",
    "copy_human_samples(DMS_samples_with_subs_path, human_DMS_samples_with_subs_path)\n",
    "copy_human_samples(DMS_samples_with_indels_path, human_DMS_samples_with_indels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wild_type_row_and_save(df_info, source_path, destination_path, filename, mutation_type):\n",
    "    \"\"\"\n",
    "    For a given DMS sample file, adds a new row with the wild type sequence and saves the modified DataFrame.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(source_path, filename)\n",
    "\n",
    "    # Extract information based on the DMS filename\n",
    "    DMS_file_info = df_info[df_info['DMS_filename'] == filename]\n",
    "\n",
    "    if not DMS_file_info.empty:\n",
    "        target_seq = DMS_file_info['target_seq'].values[0]\n",
    "        DMS_binarization_cutoff = DMS_file_info['DMS_binarization_cutoff'].values[0]\n",
    "\n",
    "        DMS_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Define a new row to be added\n",
    "        if mutation_type == 'subs':\n",
    "            new_row = {'mutant': 'Wild Type', 'mutated_sequence': target_seq, 'DMS_score': DMS_binarization_cutoff, 'DMS_score_bin': 1}\n",
    "        elif mutation_type == 'indels':\n",
    "            new_row = {'mutant': target_seq, 'DMS_score': DMS_binarization_cutoff, 'DMS_score_bin': 1}\n",
    "        \n",
    "        DMS_df = pd.concat([pd.DataFrame([new_row]), DMS_df], ignore_index=True)\n",
    "\n",
    "        # Save the updated DataFrame to a new CSV file\n",
    "        modified_filename = os.path.join(destination_path, f'modified_{filename}')\n",
    "        DMS_df.to_csv(modified_filename, index=False)\n",
    "\n",
    "\n",
    "# Process substitution samples\n",
    "for filename in os.listdir(human_DMS_samples_with_subs_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        add_wild_type_row_and_save(human_only_DMS_samples_with_subs_info_df, human_DMS_samples_with_subs_path, modified_subs_path, filename, 'subs')\n",
    "\n",
    "# Process indel samples\n",
    "for filename in os.listdir(human_DMS_samples_with_indels_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        add_wild_type_row_and_save(human_only_DMS_samples_with_indels_info_df, human_DMS_samples_with_indels_path, modified_indels_path, filename, 'indels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to scale all DMS protein fitness scores to specific scale.\n",
    "def scale_DMS_scores(data, score_column):\n",
    "    \"\"\"\n",
    "    Calculate a modified Z-score for each mutation, using the DMS score of the wild type sequence instead of the mean. This centers the data around the wild type score\n",
    "    and calculates the deviations from this score.\n",
    "    \"\"\"\n",
    "    wild_type_score = data.loc[0, score_column]\n",
    "    \n",
    "    # Calculate deviations from the wild type score\n",
    "    deviations = data[score_column] - wild_type_score\n",
    "    \n",
    "    # Square these deviations\n",
    "    squared_deviations = deviations ** 2\n",
    "    \n",
    "    # Calculate the mean of the squared deviations\n",
    "    mean_squared_deviation = squared_deviations.mean()\n",
    "    \n",
    "    # Calculate the \"custom deviation\" (similar to standard deviation but centered on the wild type score)\n",
    "    custom_deviation = np.sqrt(mean_squared_deviation)\n",
    "    \n",
    "    # Compute modified Z-scores using the custom deviation\n",
    "    data['Scaled_' + score_column] = deviations / custom_deviation\n",
    "\n",
    "    return data, wild_type_score\n",
    "\n",
    "def process_DMS_sample(file_path, score_column, drop_columns, rename_columns=None):\n",
    "    \"\"\"\n",
    "    Processes a DMS sample file by scaling scores, classifying sequences, and dropping unnecessary columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        df, cutoff_value = scale_DMS_scores(df, score_column)\n",
    "        df['State'] = df[score_column].apply(lambda x: 'Benign' if x >= cutoff_value else 'Pathogenic')\n",
    "        if rename_columns:\n",
    "            df = df.rename(columns=rename_columns)\n",
    "        df = df.drop(columns=drop_columns)\n",
    "        df = df.iloc[1:]  # Drop the row with the wild type sequence\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_directory(directory_path, score_column, drop_columns, rename_columns=None):\n",
    "    processed_samples = []\n",
    "    for filename in filter(lambda x: x.endswith('.csv'), os.listdir(directory_path)):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        processed_df = process_DMS_sample(file_path, score_column, drop_columns, rename_columns)\n",
    "        if processed_df is not None:\n",
    "            processed_samples.append(processed_df)\n",
    "    return processed_samples\n",
    "\n",
    "# Process directories and update lists\n",
    "modified_human_DMS_samples_with_subs_list = process_directory(\n",
    "    modified_subs_path, \n",
    "    'DMS_score', \n",
    "    drop_columns=['mutant', 'DMS_score_bin'])\n",
    "\n",
    "modified_human_DMS_samples_with_indels_list = process_directory(\n",
    "    modified_indels_path,'DMS_score',\n",
    "    drop_columns=['DMS_score_bin'],\n",
    "    rename_columns={'mutant': 'mutated_sequence'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to plot the results as histograms so that to study the distribution of the scaled DMS scores for each study.\n",
    "def plot_histogram(df, index, output_directory, state_column='State', score_column='DMS_score', scaled_score_column='Scaled_DMS_score'):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    # Create a subplot for the non-scaled scores\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data=df, x=score_column, hue=state_column, \n",
    "                 palette={\"Pathogenic\": \"red\", \"Benign\": \"green\"}, \n",
    "                 bins=50, alpha=0.6)\n",
    "    plt.title(f'Non-Scaled DMS Scores - Sample {index+1}')\n",
    "    plt.xlabel('DMS Score')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Create a subplot for the scaled scores\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(data=df, x=scaled_score_column, hue=state_column, \n",
    "                 palette={\"Pathogenic\": \"red\", \"Benign\": \"green\"}, \n",
    "                 bins=50, alpha=0.6)\n",
    "    plt.title(f'Scaled DMS Scores - Sample {index+1}')\n",
    "    plt.xlabel('Scaled DMS Score')\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'{output_directory}/Histogram_Comparison_{index+1}.png')\n",
    "    plt.close()\n",
    "\n",
    "for i, df in enumerate(modified_human_DMS_samples_with_subs_list):\n",
    "    plot_histogram(df, i, subs_output_directory)\n",
    "\n",
    "for i, df in enumerate(modified_human_DMS_samples_with_indels_list):\n",
    "    plot_histogram(df, i, indels_output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to build the automaton for the nullpeptide categories.\n",
    "def build_nullpeptide_automaton(nullpeptides):\n",
    "    \"\"\"\n",
    "    Creates an Aho - Corasick Automaton datastructure to store the nullpeptides.\n",
    "    \"\"\"\n",
    "    nullpeptide_automaton = ahocorasick.Automaton() # Empty Automaton list.\n",
    "    for nullpeptide in nullpeptides:\n",
    "        nullpeptide_automaton.add_word(nullpeptide, nullpeptide) # Iterates through all the nullpeptides and stores each one to the automaton datastructure.\n",
    "    nullpeptide_automaton.make_automaton()\n",
    "    return nullpeptide_automaton\n",
    "\n",
    "def read_and_build_automatons(nullpeptides_path, nullpeptide_lengths):\n",
    "    \"\"\"\n",
    "    Reads nullpeptides of specific lengths and builds corresponding automatons.\n",
    "    \"\"\"\n",
    "    automatons = {} # Initialize an empty dictionary to store automatons.\n",
    "\n",
    "    # Loop through each specified nullpeptide length.\n",
    "    for nullpeptide_length in nullpeptide_lengths:\n",
    "        try:\n",
    "            file_path = f\"{nullpeptides_path}nullpeptides_{nullpeptide_length}amino_acids_gencode.v43.pc_translations.txt\"\n",
    "            \n",
    "            # Read the nullpeptide sequences from the file into a pandas DataFrame.\n",
    "            nullpeptides_df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Convert the 'nullpeptides' column of the DataFrame into a list.\n",
    "            nullpeptides = nullpeptides_df['nullpeptides'].tolist()\n",
    "            \n",
    "            # Build an automaton for the current list of nullpeptides.\n",
    "            automatons[f'automaton_{nullpeptide_length}mer'] = build_nullpeptide_automaton(nullpeptides)\n",
    "        \n",
    "        # Catch and report any errors that occur during the process.\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing nullpeptides of length {nullpeptide_length}: {e}\")\n",
    "\n",
    "    return automatons\n",
    "\n",
    "nullpeptide_lengths = [5, 6] # Specify nullpeptide length.\n",
    "\n",
    "# Create the nullpeptides automatons.\n",
    "automatons = read_and_build_automatons(nullpeptides_path, nullpeptide_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to search the presence of each nullpeptide in the mutated sequences of the DMS experiments.\n",
    "def find_nullpeptides(sequence, nullpeptide_automaton):\n",
    "    \"\"\"\n",
    "    Searches each mutated sequence from the DMS experiments for any occurences of the nullpeptides using the previously created Automaton.\n",
    "    \"\"\"\n",
    "    nullpeptide_matches = []  # Initialize an empty list to store match information\n",
    "    for end_index, pattern in nullpeptide_automaton.iter(sequence):  \n",
    "        # Iterate over matches found by the automaton \n",
    "        start_index = end_index - len(pattern) + 1  # Calculate start of match\n",
    "        nullpeptide_matches.append((start_index, end_index, pattern)) # Store match details\n",
    "    return nullpeptide_matches  # Return the list of matches\n",
    "\n",
    "def process_DMS_sample(DMS_sample, nullpeptide_automaton, automaton_key):\n",
    "    \"\"\"\n",
    "    Searches DMS samples for present nullpeptides in mutated sequences.\n",
    "    \"\"\"\n",
    "    # Determine the nullpeptide length from the automaton key\n",
    "    length = automaton_key.split('_')[1]\n",
    "\n",
    "    # Column names for nullpeptides and their counts\n",
    "    found_nullpeptides_col = f'{length}_Nullpeptides'\n",
    "    found_nullpeptides_counts_col = f'{length}_Nullpeptides_Counts'\n",
    "\n",
    "    # Initialize columns in DataFrame\n",
    "    DMS_sample[found_nullpeptides_col] = ''\n",
    "    DMS_sample[found_nullpeptides_counts_col] = 0\n",
    "\n",
    "    # Process each row to find nullpeptides and count them\n",
    "    for index, row in tqdm(DMS_sample.iterrows(), total=len(DMS_sample), desc=f\"Processing for {length}\"):\n",
    "        matches = find_nullpeptides(row['mutated_sequence'], nullpeptide_automaton)\n",
    "        if matches:\n",
    "            matched_nullpeptides = [match[2] for match in matches]\n",
    "            DMS_sample.at[index, found_nullpeptides_col] = ', '.join(matched_nullpeptides)\n",
    "            DMS_sample.at[index, found_nullpeptides_counts_col] = len(matches)\n",
    "\n",
    "    return DMS_sample\n",
    "\n",
    "def thorough_nullpeptide_search(samples_list, automatons):\n",
    "    \"\"\"\n",
    "    Creates a final DataFrame for each DMS experiment category and searches for nullpeptides.\n",
    "    \"\"\"\n",
    "    # Concatenate and sort the samples DataFrame\n",
    "    total_samples_df = pd.concat(samples_list, ignore_index=True)\n",
    "    total_samples_df.sort_values(by=['State', 'DMS_score'], ascending=[False, False], inplace=True)\n",
    "\n",
    "    # Process for each nullpeptide category defined by automatons\n",
    "    for key, automaton in automatons.items():\n",
    "        total_samples_df = process_DMS_sample(total_samples_df, automaton, key)\n",
    "\n",
    "    # Combine found nullpeptides into a single column and sum their counts\n",
    "    nullpeptide_cols = [f'{key.split(\"_\")[1]}_Nullpeptides' for key in automatons.keys()]\n",
    "    total_samples_df['Total_Nullpeptides'] = total_samples_df[nullpeptide_cols].apply(lambda row: ', '.join(filter(None, row)), axis=1).str.strip(', ')\n",
    "\n",
    "    count_cols = [f'{key.split(\"_\")[1]}_Nullpeptides_Counts' for key in automatons.keys()]\n",
    "    total_samples_df['Total_Nullpeptide_Counts'] = total_samples_df[count_cols].sum(axis=1)\n",
    "\n",
    "    return total_samples_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for 5mer: 100%|██████████| 485830/485830 [00:15<00:00, 31045.00it/s]\n",
      "Processing for 6mer: 100%|██████████| 485830/485830 [00:27<00:00, 17859.15it/s]\n",
      "Processing for 5mer: 100%|██████████| 6967/6967 [00:00<00:00, 35730.58it/s]\n",
      "Processing for 6mer: 100%|██████████| 6967/6967 [00:00<00:00, 21518.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#Process the DMS Samples\n",
    "total_human_DMS_samples_with_subs_df = thorough_nullpeptide_search(modified_human_DMS_samples_with_subs_list, automatons)\n",
    "total_human_DMS_samples_with_indels_df = thorough_nullpeptide_search(modified_human_DMS_samples_with_indels_list, automatons)\n",
    "total_human_DMS_samples_df = pd.concat([total_human_DMS_samples_with_subs_df, total_human_DMS_samples_with_indels_df]).drop(columns='DMS_score')\n",
    "total_human_DMS_samples_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different transformations on the data to find the most appropriate one.\n",
    "def log_transform(scores):\n",
    "    \"\"\"\n",
    "    Transforms the DMS scores using the natural logarithm.\n",
    "    \"\"\"\n",
    "    if scores > 0:\n",
    "        return np.log1p(scores)\n",
    "    else:\n",
    "        return -np.log1p(-scores)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# Perform the Yeo-Johnson transformation\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "# Set score and count variables\n",
    "all_scores = total_human_DMS_samples_df[['Scaled_DMS_score']]\n",
    "\n",
    "# Perform the scaling\n",
    "total_human_DMS_samples_df['MinMax_DMS_score'] = scaler.fit_transform(all_scores)\n",
    "total_human_DMS_samples_df['YeoJohnson_DMS_score'] = pt.fit_transform(all_scores)\n",
    "total_human_DMS_samples_df['Log_DMS_score'] = total_human_DMS_samples_df['Scaled_DMS_score'].apply(log_transform)\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the distribution of the original and scaled scores using seaborn in subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "# Plot the MinMax_Scaled_DMS_score distribution\n",
    "sns.histplot(data=total_human_DMS_samples_df, x=\"MinMax_DMS_score\", hue=\"State\", palette={\"Pathogenic\": \"red\", \"Benign\": \"green\"}, bins=100, ax=axs[0,0])\n",
    "axs[0,0].set_xlabel('MinMax DMS Score')\n",
    "axs[0,0].set_ylabel('Density')\n",
    "axs[0,0].axvline(x=0.385, color='k', linestyle='--')  # Added vertical line at x=0\n",
    "\n",
    "# Plot the distribution of the total pathogenic and benign nullpeptide scaled scores.\n",
    "sns.histplot(data=total_human_DMS_samples_df, x=\"Scaled_DMS_score\", hue=\"State\", palette={\"Pathogenic\": \"red\", \"Benign\": \"green\"}, bins=100, ax=axs[0,1])\n",
    "axs[0,1].set_title(\"Distribution of Scaled DMS Scores\")\n",
    "axs[0,1].set_xlabel(\"Scaled DMS Score\")\n",
    "axs[0,1].set_ylabel(\"Frequency\")\n",
    "axs[0,1].axvline(x=0, color='k', linestyle='--')  # Added vertical line at x=0\n",
    "\n",
    "# Plot Log-transformed scores\n",
    "sns.histplot(data=total_human_DMS_samples_df, x=\"Log_DMS_score\", hue=\"State\", palette={\"Pathogenic\": \"red\", \"Benign\": \"green\"}, bins=100, ax=axs[1,0])\n",
    "axs[1,0].set_title('Log-transformed DMS Score Distribution')\n",
    "axs[1,0].set_xlabel('Log DMS Score')\n",
    "axs[1,0].set_ylabel('Frequency')\n",
    "axs[1,0].axvline(x=0, color='k', linestyle='--')  # Added vertical line at x=0\n",
    "\n",
    "# Plot Yeo-Johnson transformed scores\n",
    "sns.histplot(data=total_human_DMS_samples_df, x=\"YeoJohnson_DMS_score\", hue=\"State\", palette={\"Pathogenic\": \"red\", \"Benign\": \"green\"}, bins=100, ax=axs[1,1])\n",
    "axs[1,1].set_title('Yeo-Johnson DMS Score Distribution')\n",
    "axs[1,1].set_xlabel('Yeo-Johnson DMS Score')\n",
    "axs[1,1].set_ylabel('Frequency')\n",
    "axs[1,1].axvline(x=0, color='k', linestyle='--')  # Added vertical line at x=0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plots_directory}different_scaling_distributions.png')\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "# Drop unused columns and reorder the columns in the dataframe\n",
    "total_human_DMS_samples_df = total_human_DMS_samples_df.drop(columns=['Log_DMS_score', 'MinMax_DMS_score', 'YeoJohnson_DMS_score'])\n",
    "total_human_DMS_samples_df = total_human_DMS_samples_df[['mutated_sequence', 'Scaled_DMS_score', 'State', '5mer_Nullpeptides', '5mer_Nullpeptides_Counts', '6mer_Nullpeptides', '6mer_Nullpeptides_Counts', 'Total_Nullpeptides', 'Total_Nullpeptide_Counts']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to plot the results as barplots so that to use for the different nullpeptide lenghts.\n",
    "def barplot_nullpeptides(DMS_df, nullpeptide_column, output_filename):\n",
    "    #Count total sequences for each state.\n",
    "    total_pathogenic_count = DMS_df[DMS_df['State'] == 'Pathogenic']['mutated_sequence'].count()\n",
    "    total_benign_count = DMS_df[DMS_df['State'] == 'Benign']['mutated_sequence'].count()\n",
    "\n",
    "    #Count sequences with at least with nullpeptide present in each state.\n",
    "    pathogenic_with_nullpeptide_count = DMS_df[(DMS_df['State'] == 'Pathogenic') & (DMS_df[nullpeptide_column] > 0)]['mutated_sequence'].count()\n",
    "    benign_with_nullpeptide_count = DMS_df[(DMS_df['State'] == 'Benign') & (DMS_df[nullpeptide_column] > 0)]['mutated_sequence'].count()\n",
    "\n",
    "    #Calculate proportion of counts with nullpeptides compared to total counts.\n",
    "    proportion_pathogenic_with_nullpeptide = pathogenic_with_nullpeptide_count / total_pathogenic_count\n",
    "    proportion_benign_with_nullpeptide = benign_with_nullpeptide_count / total_benign_count\n",
    "\n",
    "    state_labels = ['Benign', 'Pathogenic']\n",
    "    proportions_values = [proportion_benign_with_nullpeptide, proportion_pathogenic_with_nullpeptide]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "    axes.bar(state_labels, proportions_values, color=['blue', 'red'])\n",
    "    axes.set_ylabel('Proportion with nullpeptides', labelpad=15)\n",
    "    axes.grid(axis='both', linestyle='-', alpha=0.7)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "\n",
    "    return proportion_benign_with_nullpeptide, proportion_pathogenic_with_nullpeptide\n",
    "\n",
    "# Calculate proportions and create the bar plot for substitution samples\n",
    "DMS_barplot_5mers = barplot_nullpeptides(total_human_DMS_samples_df, '5mer_Nullpeptides_Counts', f'{plots_directory}5mer_barplot.png')\n",
    "DMS_barplot_6mers = barplot_nullpeptides(total_human_DMS_samples_df, '6mer_Nullpeptides_Counts', f'{plots_directory}6mer_barplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate the extraction and plotting of nullpeptides counts into a single function\n",
    "def process_and_plot_nullpeptides(dataframe, state, nullpeptide_lengths, plots_directory):\n",
    "    state_df = dataframe[dataframe['State'] == state]\n",
    "    \n",
    "    for length in nullpeptide_lengths:\n",
    "        column_name = f'{length}mer_Nullpeptides_Counts'\n",
    "        counts = state_df[column_name]\n",
    "        \n",
    "        # Define the maximum count for binning based on nullpeptide length\n",
    "        max_count = length if length <= 5 else length + 1\n",
    "        \n",
    "        # Create bins with the last bin grouping all counts >= max_count.\n",
    "        bins = list(range(0, max_count)) + [max_count, counts.max() + 1]\n",
    "        \n",
    "        # Calculate histogram data\n",
    "        counts, bin_edges = np.histogram(counts, bins=bins)\n",
    "        proportions = counts / counts.sum()\n",
    "        \n",
    "        # Set bin labels, with the last label being 'max_count or more'.\n",
    "        bin_labels = [str(bin_edge) for bin_edge in bin_edges[:-2]] + [f'{max_count} or more']\n",
    "        \n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.bar(bin_labels, proportions, color='grey')\n",
    "        title = f'Proportion of {length}mer Nullpeptides in {state} Data'\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Number of Nullpeptides')\n",
    "        ax.set_ylabel('Proportion')\n",
    "        ax.set_xticks(range(len(bin_labels)))  # Set tick positions\n",
    "        ax.set_xticklabels(bin_labels, rotation=45)\n",
    "        ax.grid(True, which='both', axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        output_filepath = f'{plots_directory}/{state.lower()}_nullpeptide_proportion_{length}mer.png'\n",
    "        plt.savefig(output_filepath)\n",
    "        plt.show(fig)\n",
    "\n",
    "# Define nullpeptide lengths to process\n",
    "nullpeptide_lengths = [5, 6]\n",
    "\n",
    "# Process and plot for pathogenic data\n",
    "process_and_plot_nullpeptides(\n",
    "    dataframe=total_human_DMS_samples_df,\n",
    "    state='Pathogenic',\n",
    "    nullpeptide_lengths=nullpeptide_lengths,\n",
    "    plots_directory=plots_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pathogenic and benign scores and counts\n",
    "pathogenic_scores = total_human_DMS_samples_df.loc[total_human_DMS_samples_df[\"State\"] == \"Pathogenic\", \"Scaled_DMS_score\"]\n",
    "benign_scores = total_human_DMS_samples_df.loc[total_human_DMS_samples_df[\"State\"] == \"Benign\", \"Scaled_DMS_score\"]\n",
    "pathogenic_counts = total_human_DMS_samples_df.loc[total_human_DMS_samples_df[\"State\"] == \"Pathogenic\", \"Total_Nullpeptide_Counts\"]\n",
    "benign_counts = total_human_DMS_samples_df.loc[total_human_DMS_samples_df[\"State\"] == \"Benign\", \"Total_Nullpeptide_Counts\"]\n",
    "\n",
    "# Check normality using Shapiro-Wilk test\n",
    "pathogenic_normality = stats.shapiro(pathogenic_scores)\n",
    "benign_normality = stats.shapiro(benign_scores)\n",
    "\n",
    "# Print normality test results\n",
    "print(\"Pathogenic group:\")\n",
    "print(\"Statistic:\", pathogenic_normality.statistic)\n",
    "print(\"p-value:\", pathogenic_normality.pvalue)\n",
    "print()\n",
    "\n",
    "print(\"Benign group:\")\n",
    "print(\"Statistic:\", benign_normality.statistic)\n",
    "print(\"p-value:\", benign_normality.pvalue)\n",
    "print()\n",
    "\n",
    "# Perform Spearman correlation\n",
    "pathogenic_correlation = stats.spearmanr(pathogenic_scores, pathogenic_counts)\n",
    "benign_correlation = stats.spearmanr(benign_scores, benign_counts)\n",
    "\n",
    "# Print correlation results\n",
    "print(\"Pathogenic group:\")\n",
    "print(\"Correlation coefficient:\", pathogenic_correlation.correlation)\n",
    "print(\"p-value:\", pathogenic_correlation.pvalue)\n",
    "print()\n",
    "\n",
    "print(\"Benign group:\")\n",
    "print(\"Correlation coefficient:\", benign_correlation.correlation)\n",
    "print(\"p-value:\", benign_correlation.pvalue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = total_human_DMS_samples_df[(total_human_DMS_samples_df['Total_Nullpeptide_Counts'] > 0)]\n",
    "filtered_df = filtered_df.drop(columns=['mutated_sequence', '5mer_Nullpeptides', '5mer_Nullpeptides_Counts', '6mer_Nullpeptides', '6mer_Nullpeptides_Counts'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
